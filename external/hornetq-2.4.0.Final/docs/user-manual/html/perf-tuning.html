<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title xmlns:rf="java:org.jboss.highlight.XhtmlRendererFactory">Chapter 49. Performance Tuning</title><link rel="stylesheet" href="css/jbossorg.css" type="text/css"/><meta xmlns:rf="java:org.jboss.highlight.XhtmlRendererFactory" name="generator" content="DocBook XSL Stylesheets V1.74.0"/><meta xmlns:rf="java:org.jboss.highlight.XhtmlRendererFactory" http-equiv="Content-Type" content="text/html; charset=UTF-8"/><link rel="home" href="index.html" title="HornetQ User Manual"/><link rel="up" href="index.html" title="HornetQ User Manual"/><link rel="prev" href="interoperability.html" title="Chapter 48. Interoperability"/><link rel="next" href="configuration-index.html" title="Chapter 50. Configuration Reference"/></head><body><p id="title"><a href="http://www.jboss.org" class="site_href"><strong>JBoss.org</strong></a><a href="http://docs.jboss.org/" class="doc_href"><strong>Community Documentation</strong></a></p><ul class="docnav"><li class="previous"><a accesskey="p" href="interoperability.html"><strong>Prev</strong></a></li><li class="next"><a accesskey="n" href="configuration-index.html"><strong>Next</strong></a></li></ul><div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="perf-tuning"/>Chapter 49. Performance Tuning</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="perf-tuning.html#d0e14383">49.1. Tuning persistence</a></span></dt><dt><span class="section"><a href="perf-tuning.html#d0e14414">49.2. Tuning JMS</a></span></dt><dt><span class="section"><a href="perf-tuning.html#d0e14474">49.3. Other Tunings</a></span></dt><dt><span class="section"><a href="perf-tuning.html#d0e14579">49.4. Tuning Transport Settings</a></span></dt><dt><span class="section"><a href="perf-tuning.html#d0e14628">49.5. Tuning the VM</a></span></dt><dt><span class="section"><a href="perf-tuning.html#d0e14663">49.6. Avoiding Anti-Patterns</a></span></dt></dl></div><p>In this chapter we'll discuss how to tune HornetQ for optimum performance.</p><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="d0e14383"/>49.1. Tuning persistence</h2></div></div></div><div class="itemizedlist"><ul><li><p>Put the message journal on its own physical volume. If the disk is shared with
                    other processes e.g. transaction co-ordinator, database or other journals which
                    are also reading and writing from it, then this may greatly reduce performance
                    since the disk head may be skipping all over the place between the different
                    files. One of the advantages of an append only journal is that disk head
                    movement is minimised - this advantage is destroyed if the disk is shared. If
                    you're using paging or large messages make sure they're ideally put on separate
                    volumes too.</p></li><li><p>Minimum number of journal files. Set <code class="literal">journal-min-files</code> to a
                    number of files that would fit your average sustainable rate. If you see new
                    files being created on the journal data directory too often, i.e. lots of data
                    is being persisted, you need to increase the minimal number of files, this way
                    the journal would reuse more files instead of creating new data files.</p></li><li><p>Journal file size. The journal file size should be aligned to the capacity of
                    a cylinder on the disk. The default value 10MiB should be enough on most
                    systems.</p></li><li><p>Use AIO journal. If using Linux, try to keep your journal type as AIO. AIO
                    will scale better than Java NIO.</p></li><li><p>Tune <code class="literal">journal-buffer-timeout</code>. The timeout can be increased
                    to increase throughput at the expense of latency.</p></li><li><p>If you're running AIO you might be able to get some better performance by
                    increasing <code class="literal">journal-max-io</code>. DO NOT change this parameter if
                    you are running NIO.</p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="d0e14414"/>49.2. Tuning JMS</h2></div></div></div><p>There are a few areas where some tweaks can be done if you are using the JMS
            API</p><div class="itemizedlist"><ul><li><p>Disable message id. Use the <code class="literal">setDisableMessageID()</code> method on
                    the <code class="literal">MessageProducer</code> class to disable message ids if you don't
                    need them. This decreases the size of the message and also avoids the overhead
                    of creating a unique ID.</p></li><li><p>Disable message timestamp. Use the <code class="literal">setDisableMessageTimeStamp()</code> method on the <code class="literal">MessageProducer</code> class to disable message timestamps if you don't
                    need them.</p></li><li><p>Avoid <code class="literal">ObjectMessage</code>. <code class="literal">ObjectMessage</code> is
                    convenient but it comes at a cost. The body of a <code class="literal">ObjectMessage</code> uses Java serialization to serialize it to bytes.
                    The Java serialized form of even small objects is very verbose so takes up a lot
                    of space on the wire, also Java serialization is slow compared to custom
                    marshalling techniques. Only use <code class="literal">ObjectMessage</code> if you really
                    can't use one of the other message types, i.e. if you really don't know the type
                    of the payload until run-time.</p></li><li><p>Avoid <code class="literal">AUTO_ACKNOWLEDGE</code>. <code class="literal">AUTO_ACKNOWLEDGE</code>
                    mode requires an acknowledgement to be sent from the server for each message
                    received on the client, this means more traffic on the network. If you can, use
                        <code class="literal">DUPS_OK_ACKNOWLEDGE</code> or use <code class="literal">CLIENT_ACKNOWLEDGE</code> or a transacted session and batch up many
                    acknowledgements with one acknowledge/commit. </p></li><li><p>Avoid durable messages. By default JMS messages are durable. If you don't
                    really need durable messages then set them to be non-durable. Durable messages
                    incur a lot more overhead in persisting them to storage.</p></li><li><p>Batch many sends or acknowledgements in a single transaction. HornetQ will
                    only require a network round trip on the commit, not on every send or
                    acknowledgement.</p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="d0e14474"/>49.3. Other Tunings</h2></div></div></div><p>There are various other places in HornetQ where we can perform some tuning:</p><div class="itemizedlist"><ul><li><p>Use Asynchronous Send Acknowledgements. If you need to send durable messages
                    non transactionally and you need a guarantee that they have reached the server
                    by the time the call to send() returns, don't set durable messages to be sent
                    blocking, instead use asynchronous send acknowledgements to get your
                    acknowledgements of send back in a separate stream, see <a class="xref" href="send-guarantees.html" title="Chapter 20. Guarantees of sends and commits">Chapter 20, <i>Guarantees of sends and commits</i></a> for more information on this.</p></li><li><p>Use pre-acknowledge mode. With pre-acknowledge mode, messages are acknowledged
                        <code class="literal">before</code> they are sent to the client. This reduces the
                    amount of acknowledgement traffic on the wire. For more information on this, see
                        <a class="xref" href="pre-acknowledge.html" title="Chapter 29. Extra Acknowledge Modes">Chapter 29, <i>Extra Acknowledge Modes</i></a>.</p></li><li><p>Disable security. You may get a small performance boost by disabling security
                    by setting the <code class="literal">security-enabled</code> parameter to <code class="literal">false</code> in <code class="literal">hornetq-configuration.xml</code>.</p></li><li><p>Disable persistence. If you don't need message persistence, turn it off
                    altogether by setting <code class="literal">persistence-enabled</code> to false in
                        <code class="literal">hornetq-configuration.xml</code>.</p></li><li><p>Sync transactions lazily. Setting <code class="literal">journal-sync-transactional</code> to <code class="literal">false</code> in
                        <code class="literal">hornetq-configuration.xml</code> can give you better
                    transactional persistent performance at the expense of some possibility of loss
                    of transactions on failure. See <a class="xref" href="send-guarantees.html" title="Chapter 20. Guarantees of sends and commits">Chapter 20, <i>Guarantees of sends and commits</i></a> for more
                    information.</p></li><li><p>Sync non transactional lazily. Setting <code class="literal">journal-sync-non-transactional</code> to <code class="literal">false</code> in
                        <code class="literal">hornetq-configuration.xml</code> can give you better
                    non-transactional persistent performance at the expense of some possibility of
                    loss of durable messages on failure. See <a class="xref" href="send-guarantees.html" title="Chapter 20. Guarantees of sends and commits">Chapter 20, <i>Guarantees of sends and commits</i></a> for
                    more information.</p></li><li><p>Send messages non blocking. Setting <code class="literal">block-on-durable-send</code>
                    and <code class="literal">block-on-non-durable-send</code> to <code class="literal">false</code> in
                        <code class="literal">hornetq-jms.xml</code> (if you're using JMS and JNDI) or
                    directly on the ServerLocator. This means you don't have to wait a whole
                    network round trip for every message sent. See <a class="xref" href="send-guarantees.html" title="Chapter 20. Guarantees of sends and commits">Chapter 20, <i>Guarantees of sends and commits</i></a>
                    for more information.</p></li><li><p>If you have very fast consumers, you can increase consumer-window-size. This
                    effectively disables consumer flow control.</p></li><li><p>Socket NIO vs Socket Old IO. By default HornetQ uses old (blocking) on the
                    server and the client side (see the chapter on configuring transports for more
                    information <a class="xref" href="configuring-transports.html" title="Chapter 16. Configuring the Transport">Chapter 16, <i>Configuring the Transport</i></a>). NIO is much more scalable
                    but can give you some latency hit compared to old blocking IO. If you need to be
                    able to service many thousands of connections on the server, then you should
                    make sure you're using NIO on the server. However, if don't expect many
                    thousands of connections on the server you can keep the server acceptors using
                    old IO, and might get a small performance advantage.</p></li><li><p>Use the core API not JMS. Using the JMS API you will have slightly lower
                    performance than using the core API, since all JMS operations need to be
                    translated into core operations before the server can handle them. If using the
                    core API try to use methods that take <code class="literal">SimpleString</code> as much as
                    possible. <code class="literal">SimpleString</code>, unlike java.lang.String does not
                    require copying before it is written to the wire, so if you re-use <code class="literal">SimpleString</code> instances between calls then you can avoid some
                    unnecessary copying.</p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="d0e14579"/>49.4. Tuning Transport Settings</h2></div></div></div><div class="itemizedlist"><ul><li><p>TCP buffer sizes. If you have a fast network and fast machines you may get a
                    performance boost by increasing the TCP send and receive buffer sizes. See the
                        <a class="xref" href="configuring-transports.html" title="Chapter 16. Configuring the Transport">Chapter 16, <i>Configuring the Transport</i></a> for more information on this. </p><div xmlns:rf="java:org.jboss.highlight.XhtmlRendererFactory" class="note"><h2>Note</h2><p> Note that some operating systems like later versions of Linux include TCP
                        auto-tuning and setting TCP buffer sizes manually can prevent auto-tune from
                        working and actually give you worse performance!</p></div></li><li><p>Increase limit on file handles on the server. If you expect a lot of
                    concurrent connections on your servers, or if clients are rapidly opening and
                    closing connections, you should make sure the user running the server has
                    permission to create sufficient file handles.</p><p>This varies from operating system to operating system. On Linux systems you
                    can increase the number of allowable open file handles in the file <code class="literal">/etc/security/limits.conf</code> e.g. add the lines
                    </p><pre xmlns="" xmlns:rf="java:org.jboss.highlight.XhtmlRendererFactory" class="">
serveruser     soft    nofile  20000
serveruser     hard    nofile  20000</pre><p>
                    This would allow up to 20000 file handles to be open by the user <code class="literal">serveruser</code>. </p></li><li><p>Use <code class="literal">batch-delay</code> and set <code class="literal">direct-deliver</code>
                    to false for the best throughput for very small messages. HornetQ comes with a
                    preconfigured connector/acceptor pair (<code class="literal">netty-throughput</code>) in
                        <code class="literal">hornetq-configuration.xml</code> and JMS connection factory
                        (<code class="literal">ThroughputConnectionFactory</code>) in <code class="literal">hornetq-jms.xml</code>which can be used to give the very best
                    throughput, especially for small messages. See the <a class="xref" href="configuring-transports.html" title="Chapter 16. Configuring the Transport">Chapter 16, <i>Configuring the Transport</i></a> for more information on this.</p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="d0e14628"/>49.5. Tuning the VM</h2></div></div></div><p>We highly recommend you use the latest Java JVM for the best performance. We test
            internally using the Sun JVM, so some of these tunings won't apply to JDKs from other
            providers (e.g. IBM or JRockit)</p><div class="itemizedlist"><ul><li><p>Garbage collection. For smooth server operation we recommend using a parallel
                    garbage collection algorithm, e.g. using the JVM argument <code class="literal">-XX:+UseParallelOldGC</code> on Sun JDKs.</p></li><li><p><a id="perf-tuning.memory"/>Memory settings. Give as much memory as you can to the server. HornetQ can run
                    in low memory by using paging (described in <a class="xref" href="paging.html" title="Chapter 24. Paging">Chapter 24, <i>Paging</i></a>) but if it
                    can run with all queues in RAM this will improve performance. The amount of
                    memory you require will depend on the size and number of your queues and the
                    size and number of your messages. Use the JVM arguments <code class="literal">-Xms</code>
                    and <code class="literal">-Xmx</code> to set server available RAM. We recommend setting
                    them to the same high value.</p></li><li><p>Aggressive options. Different JVMs provide different sets of JVM tuning
                    parameters, for the Sun Hotspot JVM the full list of options is available <a class="ulink" href="http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html">here</a>. We recommend at least using <code class="literal">-XX:+AggressiveOpts</code> and<code class="literal">
                        -XX:+UseFastAccessorMethods</code>. You may get some mileage with the
                    other tuning parameters depending on your OS platform and application usage
                    patterns.</p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="d0e14663"/>49.6. Avoiding Anti-Patterns</h2></div></div></div><div class="itemizedlist"><ul><li><p>Re-use connections / sessions / consumers / producers. Probably the most
                    common messaging anti-pattern we see is users who create a new
                    connection/session/producer for every message they send or every message they
                    consume. This is a poor use of resources. These objects take time to create and
                    may involve several network round trips. Always re-use them.</p><div xmlns:rf="java:org.jboss.highlight.XhtmlRendererFactory" class="note"><h2>Note</h2><p>Some popular libraries such as the Spring JMS Template are known to use
                        these anti-patterns. If you're using Spring JMS Template and you're getting
                        poor performance you know why. Don't blame HornetQ! The Spring JMS Template
                        can only safely be used in an app server which caches JMS sessions (e.g.
                        using JCA), and only then for sending messages. It cannot be safely be used
                        for synchronously consuming messages, even in an app server. </p></div></li><li><p>Avoid fat messages. Verbose formats such as XML take up a lot of space on the
                    wire and performance will suffer as result. Avoid XML in message bodies if you
                    can.</p></li><li><p>Don't create temporary queues for each request. This common anti-pattern
                    involves the temporary queue request-response pattern. With the temporary queue
                    request-response pattern a message is sent to a target and a reply-to header is
                    set with the address of a local temporary queue. When the recipient receives the
                    message they process it then send back a response to the address specified in
                    the reply-to. A common mistake made with this pattern is to create a new
                    temporary queue on each message sent. This will drastically reduce performance.
                    Instead the temporary queue should be re-used for many requests.</p></li><li><p>Don't use Message-Driven Beans for the sake of it. As soon as you start using
                    MDBs you are greatly increasing the codepath for each message received compared
                    to a straightforward message consumer, since a lot of extra application server
                    code is executed. Ask yourself do you really need MDBs? Can you accomplish the
                    same task using just a normal message consumer?</p></li></ul></div></div></div><ul class="docnav"><li class="previous"><a accesskey="p" href="interoperability.html"><strong>Prev</strong>Chapter 48. Interoperability</a></li><li class="up"><a accesskey="u" href="#"><strong>Top of page</strong></a></li><li class="home"><a accesskey="h" href="index.html"><strong>Front page</strong></a></li><li class="next"><a accesskey="n" href="configuration-index.html"><strong>Next</strong>Chapter 50. Configuration Reference</a></li></ul></body></html>